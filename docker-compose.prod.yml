# Production Docker Compose configuration
version: '3.8'

services:
  # Frontend (Next.js)
  frontend:
    build:
      context: ./frontend
      target: production
    container_name: interview-coach-frontend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=https://api.yourdomain.com
      - NEXT_PUBLIC_WS_URL=wss://ws.yourdomain.com
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "const http = require('http'); const options = { host: 'localhost', port: 3000, timeout: 2000 }; const request = http.request(options, (res) => { console.log('STATUS: ' + res.statusCode); process.exitCode = (res.statusCode == 200) ? 0 : 1; process.exit(); }); request.on('error', function(err) { console.log('ERROR: ' + err); process.exit(1); }); request.end();"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - interview-helper
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # FastAPI evaluation service
  fastapi:
    build: 
      context: ./backend/backend/fastapi
      target: production
    container_name: interview-coach-api
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - WORKERS=4
      - HOST=0.0.0.0
      - PORT=8000
    env_file:
      - .env.production
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - interview-helper
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # WebSocket transcription service
  websocket:
    build: 
      context: ./backend/backend/websocket
      target: production
    container_name: interview-coach-ws
    ports:
      - "8001:8001"
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - WS_PORT=8001
      - WS_HOST=0.0.0.0
      - MAX_CLIENTS=50
    env_file:
      - .env.production
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(5); s.connect(('localhost', 8001)); s.close()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - interview-helper
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '1.0'
          memory: 2G
    # Uncomment for audio device access in production
    # devices:
    #   - "/dev/snd:/dev/snd"
    # privileged: true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis for caching and session management
  redis:
    image: redis:7.2-alpine
    container_name: interview-coach-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./backend/redis/redis.conf:/etc/redis/redis.conf:ro
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - interview-helper
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Nginx reverse proxy
  nginx:
    image: nginx:1.25-alpine
    container_name: interview-coach-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./backend/nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./backend/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - fastapi
      - websocket
      - frontend
    restart: unless-stopped
    networks:
      - interview-helper
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: interview-coach-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./backend/monitoring/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - ./backend/monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped
    networks:
      - interview-helper
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Grafana for visualization
  grafana:
    image: grafana/grafana:10.2.0
    container_name: interview-coach-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./backend/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./backend/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - interview-helper
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: interview-coach-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - interview-helper
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

volumes:
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  interview-helper:
    driver: bridge
    name: interview-helper-network
    ipam:
      config:
        - subnet: 172.20.0.0/16
